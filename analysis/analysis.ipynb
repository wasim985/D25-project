{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Initialization\n",
    "First Let's load the data and word embeddings. Note the original paper only used data from 2017 and top 10k subreddits. \\\n",
    "For sake of time we shall use data from 2017 only and top 5k subreddits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wasimroks\\AppData\\Local\\Temp\\ipykernel_19516\\1438605563.py:4: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('text_submissions.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3496180, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the data and filter accordingly\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('text_submissions.csv')\n",
    "df2 = pd.read.csv('text_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_parse doesn't work well with seconds notation, parse them ourselves\n",
    "df['created_utc'] = pd.to_numeric(df['created_utc'], errors='coerce')\n",
    "df['time'] = pd.to_datetime(df['created_utc'],utc=True,unit='s')\n",
    "df2['created_utc'] = pd.to_numeric(df2['created_utc'], errors='coerce')\n",
    "df2['time'] = pd.to_datetime(df2['created_utc'],utc=True,unit='s')\n",
    "\n",
    "df = df.dropna()\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and Create word2vec embeddings of the reddit communities \\\n",
    "Calculate GS-Scores as outlined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize NLTK to conduct sentiment analysis on comments / submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>is_self</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_npxigk</td>\n",
       "      <td>All_Consuming_Void</td>\n",
       "      <td>1.622564e+09</td>\n",
       "      <td>self.BeautyGuruChatter</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Hyram launches his own brand</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>2021-06-01 16:06:55+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_nqj6bf</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.622632e+09</td>\n",
       "      <td>self.BeautyGuruChatter</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>What are the influencers trying to influence y...</td>\n",
       "      <td>What I'm not gonna buy Wednesday - Anti-haul</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>2021-06-02 11:00:21+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_nk0btr</td>\n",
       "      <td>barrahhhh</td>\n",
       "      <td>1.621869e+09</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plouise goes off in facebook group for 'bullying'</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>2021-05-24 15:17:19+00:00</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_nrbybs</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1.622722e+09</td>\n",
       "      <td>self.BeautyGuruChatter</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Is youtube algorithm against Susan Yara? She g...</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>2021-06-03 12:11:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_nl0ebd</td>\n",
       "      <td>carlosShook</td>\n",
       "      <td>1.621978e+09</td>\n",
       "      <td>vm.tiktok.com</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sephora steals concept from Huntr Faulknr afte...</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>2021-05-25 21:22:47+00:00</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>t3_o9fvct</td>\n",
       "      <td>Both_Luck6987</td>\n",
       "      <td>1.624868e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8670Shout 8670out 8670Lit 8670Papi8670</td>\n",
       "      <td>FreeKarma4U</td>\n",
       "      <td>2021-06-28 08:15:26+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>t3_nnj427</td>\n",
       "      <td>Both_Luck6987</td>\n",
       "      <td>1.622278e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639Shout 639out 639Lit 639Papi639</td>\n",
       "      <td>FreeKarma4U</td>\n",
       "      <td>2021-05-29 08:40:12+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>t3_o9fw19</td>\n",
       "      <td>Both_Luck6987</td>\n",
       "      <td>1.624868e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6525Shout 6525out 6525Lit 6525Papi6525</td>\n",
       "      <td>FreeKarma4U</td>\n",
       "      <td>2021-06-28 08:16:57+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>t3_o9fw3k</td>\n",
       "      <td>Both_Luck6987</td>\n",
       "      <td>1.624868e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5969Shout 5969out 5969Lit 5969Papi5969</td>\n",
       "      <td>FreeKarma4U</td>\n",
       "      <td>2021-06-28 08:17:05+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>t3_nnj4pj</td>\n",
       "      <td>Both_Luck6987</td>\n",
       "      <td>1.622278e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>791Shout 791out 791Lit 791Papi791</td>\n",
       "      <td>FreeKarma4U</td>\n",
       "      <td>2021-05-29 08:41:36+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id              author   created_utc                  domain  \\\n",
       "0      t3_npxigk  All_Consuming_Void  1.622564e+09  self.BeautyGuruChatter   \n",
       "1      t3_nqj6bf       AutoModerator  1.622632e+09  self.BeautyGuruChatter   \n",
       "2      t3_nk0btr           barrahhhh  1.621869e+09              reddit.com   \n",
       "3      t3_nrbybs           [deleted]  1.622722e+09  self.BeautyGuruChatter   \n",
       "4      t3_nl0ebd         carlosShook  1.621978e+09           vm.tiktok.com   \n",
       "...          ...                 ...           ...                     ...   \n",
       "99995  t3_o9fvct       Both_Luck6987  1.624868e+09               i.redd.it   \n",
       "99996  t3_nnj427       Both_Luck6987  1.622278e+09               i.redd.it   \n",
       "99997  t3_o9fw19       Both_Luck6987  1.624868e+09               i.redd.it   \n",
       "99998  t3_o9fw3k       Both_Luck6987  1.624868e+09               i.redd.it   \n",
       "99999  t3_nnj4pj       Both_Luck6987  1.622278e+09               i.redd.it   \n",
       "\n",
       "      is_self  score                                           selftext  \\\n",
       "0        True    0.0                                          [removed]   \n",
       "1        True   38.0  What are the influencers trying to influence y...   \n",
       "2       False  144.0                                                NaN   \n",
       "3        True    2.0                                          [deleted]   \n",
       "4       False    0.0                                                NaN   \n",
       "...       ...    ...                                                ...   \n",
       "99995   False    1.0                                                NaN   \n",
       "99996   False    1.0                                                NaN   \n",
       "99997   False    1.0                                                NaN   \n",
       "99998   False    1.0                                                NaN   \n",
       "99999   False    1.0                                                NaN   \n",
       "\n",
       "                                                   title          subreddit  \\\n",
       "0                           Hyram launches his own brand  BeautyGuruChatter   \n",
       "1           What I'm not gonna buy Wednesday - Anti-haul  BeautyGuruChatter   \n",
       "2      Plouise goes off in facebook group for 'bullying'  BeautyGuruChatter   \n",
       "3      Is youtube algorithm against Susan Yara? She g...  BeautyGuruChatter   \n",
       "4      Sephora steals concept from Huntr Faulknr afte...  BeautyGuruChatter   \n",
       "...                                                  ...                ...   \n",
       "99995             8670Shout 8670out 8670Lit 8670Papi8670        FreeKarma4U   \n",
       "99996                  639Shout 639out 639Lit 639Papi639        FreeKarma4U   \n",
       "99997             6525Shout 6525out 6525Lit 6525Papi6525        FreeKarma4U   \n",
       "99998             5969Shout 5969out 5969Lit 5969Papi5969        FreeKarma4U   \n",
       "99999                  791Shout 791out 791Lit 791Papi791        FreeKarma4U   \n",
       "\n",
       "                           time  compound    neg    neu  pos  \n",
       "0     2021-06-01 16:06:55+00:00    0.0000  0.000  1.000  0.0  \n",
       "1     2021-06-02 11:00:21+00:00    0.0000  0.000  1.000  0.0  \n",
       "2     2021-05-24 15:17:19+00:00   -0.5994  0.358  0.642  0.0  \n",
       "3     2021-06-03 12:11:00+00:00    0.0000  0.000  1.000  0.0  \n",
       "4     2021-05-25 21:22:47+00:00   -0.5106  0.231  0.769  0.0  \n",
       "...                         ...       ...    ...    ...  ...  \n",
       "99995 2021-06-28 08:15:26+00:00    0.0000  0.000  1.000  0.0  \n",
       "99996 2021-05-29 08:40:12+00:00    0.0000  0.000  1.000  0.0  \n",
       "99997 2021-06-28 08:16:57+00:00    0.0000  0.000  1.000  0.0  \n",
       "99998 2021-06-28 08:17:05+00:00    0.0000  0.000  1.000  0.0  \n",
       "99999 2021-05-29 08:41:36+00:00    0.0000  0.000  1.000  0.0  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Utilize NLTK\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "#Test on small dataset for now\n",
    "test = df.copy().iloc[:100000,:]\n",
    "test['compound'] = [analyzer.polarity_scores(x)['compound'] for x in test['title']]\n",
    "test['neg'] = [analyzer.polarity_scores(x)['neg'] for x in test['title']]\n",
    "test['neu'] = [analyzer.polarity_scores(x)['neu'] for x in test['title']]\n",
    "test['pos'] = [analyzer.polarity_scores(x)['pos'] for x in test['title']]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS-Score and Sentiment relationship\n",
    "Investigate and study relationship between sentiment and GS-scores \\\n",
    "Utilize Vader to study basic emotions such as positive, negative, neutral \\\n",
    "Visualize as line graph of GS-score vs each sentiment \\\n",
    "Breakdown Average community sentiment along with communities as a Grid \\\n",
    "Hypothesis to test: Can GS-scores of communities contribute to their emotions and strenght? \\\n",
    "                    Are specialists more likely to be enthusiastic, since they are more picky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS-Score and submission statistics\n",
    "Compare submissions and comments of each user \\\n",
    "Utilize the ratio of submissions vs comments in a time frame to see if the user is a actively creating \\\n",
    "Categorize users as active creators \\\n",
    "Investigate the communities the user likes to submit in, is it similar to the ones they comment in (Ones used to make gs scores) \\\n",
    "Train a model with and without GS-scores to see if active contributors can be identified \\\n",
    "Compare Elite posters (top 5% posts) with community GS-scores, the original paper suggested elite commenters are generalists, is it also true for posters? \\\n",
    "Hypothesis to tess: Can GS-Score be a good indicator of active contributer (likes to create submissions)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
